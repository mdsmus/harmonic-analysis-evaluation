\section{Introduction}
\label{sec:introduction}

Chord labeling consists in assigning a name to a set of notes. The
process involves dividing a musical score in symbolic format into
different sonorities, deciding which notes in a sonority are part of a
chord, and naming the sonorities with symbols like E$\flat$ or
A$\sharp$7M.

The problem of automatic chord labeling of symbolic scores has been
approached from many angles since the sixties. First, Winograd
\cite{winograd68:linguistics} and Ulrich \cite{ulrich77:analysis}
developed backtracking parsers based on formal grammars and
productions. After a hiatus they were followed by Maxwell's
\cite{maxwell92:expert} rule-based expert system and Temperley and
Sleator's preference-rule Melisma system
\cite{temperley.ea99:modeling}. In the end of the nineties Pardo and
Birmingham's HarmAn \cite{pardo.ea02:algorithms}, Barthelemy and
Bonardi's algorithm \cite{barthelemy.ea01:figured}, and Taube's
workbench \cite{taube99:automatic} were built, all using
pattern-matching as their core chord-finding method. Parallel to these
are Tsui's neural network algorithm \cite{tsui02:harmonic},
Temperley's bayesian approach \cite{temperley04:bayesian}, and Raphael
and Stoddard's hidden Markov model \cite{raphael.ea03:harmonic}.
Recently, Illescas et al. designed a mixed system, based on rules and
search through a graph of possible solutions
\cite{illescas.ea07:harmonic}.


\begin{table}[!h]
\centering
\begin{tabular}{r|l|r}
chord & meaning                   & count\\ \hline
    M & major chord               & 773 \\
   M7 & major chord, minor seventh& 182 \\
  M7+ & major chord, major seventh& 20 \\
    m & minor chord               & 311 \\
   m7 & minor chord, minor seventh& 109 \\
    ° & diminished triad          & 91 \\
   °7 & fully diminished chord    & 30 \\
   ø7 & half-diminished chord     & 44  \\
  aug & augmented chord           & 2   \\
  inc & incomplete chord          & 4   \\
 aug6 & augmented sixth chord     & 3   \\
  nct & non-chord tone            & 410 \\
\end{tabular}
\caption{Chord labels used in this article and their occurrences in our
corpus}
\label{tab:legenda}
\end{table}



Most of these techniques and methods are not described rigorously, and
very little source code is available for testing. For example,
Barthelemy and Bonardi \cite{pardo.ea02:algorithms} and Temperley and
Sleator \cite{temperley.ea99:modeling}, don't provide enough
information to reproduce their results reliably. Every benchmark found
in literature
\cite{pardo.ea00:automated,pardo.ea02:algorithms,tsui02:harmonic,taube99:automatic,illescas.ea07:harmonic}
is based only on published examples, and this makes difficult a
thorough statistical evaluation of the main merits and flaws of each
technique.

To correct this deficiency we have reimplemented and evaluated some
chord labeling algorithms in a precise statistical framework. This
evaluation is performed on Bach Chorales, and we describe our
methodology in section \ref{sec:methodology}. The chord types we
consider are shown in table \ref{tab:legenda}. The algorithms we
reimplemented (and the algorithms we present in this paper) are
described in section \ref{sec:algorithms}. We compare their overall
performance in section \ref{sec:discussion} and state our case in
section \ref{sec:conclusions}.


\section{Methodology}
\label{sec:methodology}


To concisely show most of the errors made by the algorithms considered
in this paper we propose a different evaluation methodology: each
algorithm will be evaluated by their precision and recall with respect
to each chord mode, highlighting many weaknesses. This decision is a
bit unusual, and deserves justification. Here, we assume that the aim
of our algorithms is to retrieve correctly each sonority belonging to
a certain chord type from a song. We also treat the detection of each
chord type separately. Hence, every time a diminished chord is
misclassified as a non chord tone, for example, the recall of
diminished chords gets smaller, while the precision of the non-chord
tones get smaller. As shown is section \ref{sec:discussion}, Pardo and
Birmingham's algorithm has a high recall and a small precision,
probably due to its incapacity of handling non-chord tones; and the
machine learning algorithm are mostly biased against less frequent
chord types.

We will perform this evaluation on a corpus of 28 Bach chorales from
the Riemenschneider edition \cite{bach41:371}, consisting of the
chorales numbered 7, 8, 10, 12, 14, 17, 18, 19, 20, 21, 22, 23, 24,
25, 26, 27, 28, 29, 30, 31, 32, 33, 36, 40, 140, 146, 162, and 340. We
wrote answer sheets for each chorale with the chord label for each
segment. With these answer sheets, our system is able to automatically
compare the results of each algorithm with the correct result as
analyzed by musicians. The code and data used in this evaluation,
together with instructions to reproduce our analysis, are available
on-line at \url{http://removed-for-anonymity}\footnote{The real URL
  will be added in the camera-ready version.}.

\section{Algorithms}
\label{sec:algorithms}


Chord labeling is a classification problem, consisting of labeling
each sonority (or sequence of sonorities) in a score with a chord
type. Most classification algorithms operate on a set of features,
that are previously extracted from the data. This is done mainly to
remove irregularities in the original inputs and reduce the
dimensionality of the problem, thereby making it more tractable. Each
classification algorithm we present operates on a distinct set of
features, mostly derived from the pitches of the notes. Metrical
information is not considered in any algorithm discussed here.

In this section we present Pardo and Birmingham's algorithm and a few
machine learning techniques. The machine learning algorithms were
trained on the chorales numbered 1, 2, 3, 4, 5, and 6 of the
Riemenschneider edition and on some textbook examples of augmented
sixths, augmented chords, and major chords with major sevenths
extracted from Robert Gauldin \cite{gauldin05:harmonic} and Reginald
Morris \cite{morris33:figured}. 

\subsection{Pardo and Birmingham's algorithm}
\label{sec:pardo}


Pardo and Birmingham \cite{barthelemy.ea01:figured} describe a
pattern-matching algorithm for chordal analysis based on templates.
The article enumerates six templates, and the algorithm searches
across the piece for the labeling that better matches the notes found.
When a tie happens between two templates, a tie-breaking heuristic is
used (one such heuristic is ``prefer more common labelings''). In
practice, most of the non-trivial decisions made by this algorithm are
codified as tie-breaking rules, and this approach doesn't scale
well. Raphael and Stoddard describe problems common to rule based
systems \cite{raphael.ea03:harmonic}, and we have found that most of
them also apply to Pardo and Birmingham's algorithm.

Some limitations are described in the article. The algorithm, for
example, has no notion of a minor chord with a minor seventh, or an
augmented chord, or a chord without a third. Also, since their system
ignores enharmonic information some fine distinctions are lost, and a
German augmented sixth is shown being classified erroneously as a
dominant seventh. We have then extended the algorithm presented in the
article by incorporating more chord templates (giving a total of ten)
and enabling it to distinguish enharmonic tones, which improved the
recall of fully diminished chords and the precision in recognizing
major chords, as seen in section \ref{sec:discussion}. We have also
added inversion detection. The original algorithm is referred to as
\texttt{S-pb} and our extended version as \texttt{ES-pb}.

\subsection{Decision Tree}
\label{sec:tree}

Our decision tree uses the ID3 algorithm \cite{mitchell97:machine}.
Since our decision tree library can't handle numeric attributes well,
the features we use for classifying a sonority are its four
pitches. This, unfortunately, makes it impossible for this algorithm
to generalize to musical styles not very similar to a four-part
chorale, although we plan on extending it to overcome this
limitation. The algorithm is named \texttt{ES-tree}. It distinguishes
enharmonic notes but ignores the surrounding context.

\subsection{Artificial Neural Networks}
\label{sec:neural-net}


The artificial neural networks we used are modeled after Tsui's Root
Network A \cite{tsui02:harmonic}. The main differences are the feature
extraction process and our considering chord types other than major
and minor. Tsui uses as features a vector, each position containing
how many times one pitch class sounds in a given sonority.  On
training, Tsui's algorithm first transposes each sonority to the 12
possible pitch classes to ensure that the network is invariant under
transposition. While interesting, this approach becomes
computationally prohibitive if one wants to distinguish enharmonic
notes. Instead, we chose to transpose each sonority so that it has C
as its lowest note. This codification is transposition invariance and
allows a much simpler network structure.

We implemented two neural network algorithms: \texttt{ES-net}, which
does not use contextual information, and \texttt{EC-net}, which
does. Both distinguish enharmonic notes.  It should be noted that,
unlike Tsui, our neural networks have an overall worse accuracy when
context is added, as can be seen in section \ref{sec:discussion}. Our
experiments determined that the best amount of contextual information
is the least possible, so \texttt{EC-net} looks only at one preceding
and one following sonority.


\subsection{K-Nearest-Neighbors}
\label{sec:knn}

We implemented a k-nearest-neighbors algorithm because it has good
performance and is easy to implement
\cite{fix.ea89:important,gomez.ea04:estimating}. The features used in
this classifier were the same as in the neural networks. Our two
k-nearest-neighbor algorithms, \texttt{ES-knn} and \texttt{EC-knn},
distinguish enharmonic notes, and the only difference between them is
that \texttt{ES-knn} looks at one sonority at a time, while
\texttt{EC-knn} also receives information from surrounding sonorities
as input. 

\section{Results}
\label{sec:discussion}

\begin{table}
\subfloat[Precision (\%)]{
\begin{tabular}{r|p{0.5cm}p{0.5cm}p{0.5cm}p{0.5cm}p{0.5cm}p{0.5cm}p{0.5cm}p{0.5cm}}
     &   EC-Knn &   EC-net &   ES-Knn &   ES-net &    ES-PB &  ES-tree &   S-PB \\ \hline
   M & $  88.4$ & $  94.4$ & $  95.8$ & $  97.7$ & $  90.6$ & $  89.2$ & $  71.4$ \\
  M7 & $  85.3$ & $  91.0$ & $  89.7$ & $  94.1$ & $  75.0$ & $  82.9$ & $  74.1$ \\
 M7+ & $  50.0$ & $  25.0$ & $ ~~0.0$ & $ 100  $ & $  38.6$ & $ ~~0.0$ & $ ~~0.0$ \\
   m & $  82.7$ & $  89.5$ & $  89.4$ & $  94.6$ & $  83.9$ & $  83.8$ & $  83.6$ \\
  m7 & $  65.5$ & $  66.2$ & $  76.9$ & $  80.3$ & $  86.3$ & $  54.8$ & $ ~~0.0$ \\
  °  & $  86.0$ & $  71.0$ & $  90.0$ & $  95.2$ & $  87.1$ & $  70.4$ & $  83.5$ \\
 °7  & $  87.5$ & $  54.5$ & $ 100$   & $  90.9$ & $  96.8$ & $  51.4$ & $ 100$ \\
 ø7  & $  60.6$ & $  50.0$ & $  97.3$ & $  89.8$ & $  50.0$ & $  71.1$ & $  49.5$ \\
 aug & $ ~~0.0$ & $ 100  $ & $ ~~0.0$ & $ ~~0.0$ & $  28.6$ & $ ~~0.0$ & $ ~~0.0$ \\
 inc & $ ~~0.0$ & $ ~~0.0$ & $ ~~0.0$ & $ ~~0.0$ & $ ~~2.5$ & $ ~~0.0$ & $ ~~0.0$ \\
aug6 & $  50.0$ & $  12.5$ & $ 100  $ & $ 100  $ & $  50.0$ & $ ~~0.0$ & $ ~~0.0$ \\
 nct & $  74.1$ & $  76.6$ & $  80.8$ & $  88.3$ & $ ~~0.0$ & $  70.0$ & $ ~~0.0$ \\
\hline                                                       
avg & $   60.8$ & $  60.9$ & $  68.3$ & $  77.6$ & $  57.4$ & $  47.8$ & $  38.5$ \\
\end{tabular}
\label{tab:precision}
}
\subfloat[Recall (\%)]{
\begin{tabular}{r|p{0.5cm}p{0.5cm}p{0.5cm}p{0.5cm}p{0.5cm}p{0.5cm}p{0.5cm}p{0.5cm}}
     &   EC-Knn &   EC-net &   ES-Knn &   ES-net &    ES-PB &  ES-tree &     S-PB \\ \hline
   M & $  95.2$ & $  97.3$ & $  98.3$ & $  98.7$ & $  97.2$ & $  96.3$ & $  99.7$ \\
  M7 & $  78.4$ & $  87.6$ & $  94.1$ & $  95.1$ & $  96.3$ & $  62.0$ & $  96.8$ \\
 M7+ & $  12.5$ & $ ~~4.5$ & $ ~~0.0$ & $ ~~4.5$ & $  96.4$ & $ ~~0.0$ & $ ~~0.0$ \\
   m & $  87.7$ & $  88.7$ & $  95.9$ & $  98.4$ & $  98.8$ & $  89.3$ & $  98.4$ \\
  m7 & $  66.1$ & $  78.6$ & $  83.0$ & $  94.6$ & $  77.9$ & $  56.8$ & $ ~~0.0$ \\
   ° & $  80.0$ & $  71.7$ & $  97.1$ & $  98.0$ & $  99.0$ & $  57.0$ & $  99.0$ \\
  °7 & $  70.0$ & $  20.0$ & $  70.0$ & $ 100  $ & $ 100  $ & $  60.0$ & $  86.7$ \\
  ø7 & $  42.6$ & $  21.3$ & $  76.6$ & $  93.6$ & $  97.9$ & $  56.2$ & $ 100$ \\
 aug & $ ~~0.0$ & $  50.0$ & $ ~~0.0$ & $ ~~0.0$ & $ 100  $ & $ ~~0.0$ & $ ~~0.0$ \\
 inc & $ ~~0.0$ & $ ~~0.0$ & $ ~~0.0$ & $ ~~0.0$ & $  50.0$ & $ ~~0.0$ & $ ~~0.0$ \\
aug6 & $  66.7$ & $  33.3$ & $ 100  $ & $ 100  $ & $ 100  $ & $ ~~0.0$ & $ ~~0.0$ \\
 nct & $  69.5$ & $  81.9$ & $  75.1$ & $  82.3$ & $ ~~0.0$ & $  69.8$ & $ ~~0.0$ \\
\hline                                                       
 avg & $  55.7$ & $  52.9$ & $  65.8$ & $  72.1$ & $  84.5$ & $  45.6$ & $  48.4$ \\
\end{tabular}
\label{tab:recall}
}

\subfloat[F-measure (\%)]{
\begin{tabular}{r|p{0.5cm}p{0.5cm}p{0.5cm}p{0.5cm}p{0.5cm}p{0.5cm}p{0.5cm}p{0.5cm}}
     &   EC-Knn &   EC-net &   ES-Knn &   ES-net &    ES-PB &  ES-tree &        S-PB \\ \hline
   M & $  91.7$ & $  95.8$ & $  97.0$ & $  98.2$ & $  93.8$ & $  92.6$ & $  83.2$ \\
  M7 & $  81.7$ & $  89.3$ & $  91.8$ & $  94.6$ & $  84.3$ & $  70.9$ & $  83.9$ \\
 M7+ & $  20.0$ & $ ~~7.6$ & $ ~~0.0$ & $ ~~8.6$ & $  55.1$ & $ ~~0.0$ & $ ~~0.0$ \\
   m & $  85.1$ & $  89.1$ & $  92.5$ & $  96.5$ & $  90.7$ & $  86.5$ & $  90.4$ \\
  m7 & $  65.8$ & $  71.9$ & $  79.8$ & $  86.9$ & $  81.9$ & $  55.8$ & $ ~~0.0$ \\
   ° & $  82.9$ & $  71.3$ & $  93.4$ & $  96.6$ & $  92.7$ & $  63.0$ & $  90.6$ \\
  °7 & $  77.8$ & $  29.3$ & $  82.4$ & $  95.2$ & $  98.4$ & $  55.4$ & $  92.9$ \\
  ø7 & $  50.0$ & $  29.9$ & $  85.7$ & $  91.7$ & $  66.2$ & $  62.8$ & $  66.2$ \\
 aug & $ ~~0.0$ & $  66.7$ & $ ~~0.0$ & $ ~~0.0$ & $  44.5$ & $ ~~0.0$ & $ ~~0.0$ \\
 inc & $ ~~0.0$ & $ ~~0.0$ & $ ~~0.0$ & $ ~~0.0$ & $ ~~4.8$ & $ ~~0.0$ & $ ~~0.0$ \\
aug6 & $  57.2$ & $  18.2$ & $ 100  $ & $ 100  $ & $  66.7$ & $ ~~0.0$ & $ ~~0.0$ \\
 nct & $  71.7$ & $  79.2$ & $  77.8$ & $  85.2$ & $ ~~0.0$ & $  69.9$ & $ ~~0.0$ \\
\hline                                                       
 avg & $  57.0$ & $  54.0$ & $  66.7$ & $  71.1$ & $  64.9$ & $  46.4$ & $  42.3$ \\
\end{tabular}
  \label{tab:f-measure}
}
\subfloat[Overall Accuracy (\%)]{
  \begin{tabular}{l|rrr}
       & accuracy& $\sigma$  & f-measure\\
\hline
ES-net &$   93  $&$  3$      &$71.1$ \\
ES-knn &$   90  $&$  4$      &$66.7$ \\
EC-net &$   85  $&$  5$      &$54.0$ \\
EC-knn &$   82  $&$  4$      &$57.0$ \\
ES-pb  &$   80  $&$  5$      &$64.9$ \\
ES-tree&$   79  $&$  7$      &$46.4$ \\
S-pb   &$   68  $&$ 15$      &$42.3$ \\
  \end{tabular}                                                        
  \label{tab:accuracy}
}
\end{table}


The results are displayed in a few tables. Tables \ref{tab:precision},
\ref{tab:recall}, and \ref{tab:f-measure} show the precision, recall
and f-measure of the evaluated algorithms. Table \ref{tab:accuracy}
shows their overall accuracy across all chords in our corpus.

\subsection{Performance by algorithm}
\label{sec:algo-perf}

The performance of Pardo and Birmingham's original algorithm,
\texttt{S-pb}, is very low on our corpus due to the variety of chord
types considered. 

The decision tree algorithm's performance is unremarkable in
comparison with the other machine learning algorithms. It displays the
smallest ability to generalize from training data, probably due to a
bad choice of features.

The contextual algorithms, \texttt{EC-knn} and \texttt{EC-net}, are
overall worse than their non-contextual equivalents, probably due to
having a smaller performance on the more common chord modes. On the
other hand, \texttt{EC-net} is the only machine learning algorithm
that is able to recognize augmented chords and \texttt{EC-knn}, unlike
\texttt{ES-knn}, recognizes major chords with a major seventh.


Overall, \texttt{ES-net} has the best precision, f-measure and
accuracy, as seen in tables \ref{tab:precision}, \ref{tab:f-measure},
and \ref{tab:accuracy}; but \texttt{ES-pb} has the best recall. This
is most likely due to \texttt{ES-pb}'s ignorance of non-chord
tones. 


\section{Conclusions and future work}
\label{sec:conclusions}

We have evaluated algorithms for chord labeling of symbolic scores of
tonal music on a corpus of 28 Bach chorales and have found that an
artificial neural network that does not use contextual information is
the best algorithm evaluated. We have also found that a simple
memory-based classifier can outperform a simple heuristic algorithm,
although with better heuristics this result might be reversed. We also
presented a modification to the algorithm described in
\cite{pardo.ea02:algorithms} that is demonstrably better.

We currently plan on continuing to reimplement, test, and benchmark
algorithms for automated chord labeling and harmonic analysis,
starting with Raphael and Stoddard's hidden Markov model
\cite{raphael.ea03:harmonic} and Maxwell's expert system
\cite{maxwell92:expert}.  We will extend our test corpus to
incorporate Beethoven sonatas, the Kostka-Payne corpus
\cite{temperley04:bayesian}, Bach partitas, and other classic tonal
pieces. Our aim is to benchmark and study the whole automatic harmonic
analysis process, from pitch spelling to functional and non-chord tone
analysis.

%%% Local Variables: 
%%% mode: latex
%%% TeX-master: "harmonic-analysis-evaluation-anppom"
%%% End: 
