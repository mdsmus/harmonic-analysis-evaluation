\documentclass{article}
\usepackage{ismir}
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage{url}
\usepackage[utf8x]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[english]{babel}
%\usepackage[htt]{hyphenat}
\usepackage{times}
\usepackage{color}
\usepackage[displaymath,textmath,sections,graphics,floats,auctex]{preview}

\newcounter{notecounter}

\newcommand{\note}[1]{
  \addtocounter{notecounter}{1}
  \textcolor{red}{[note \arabic{notecounter}: #1]}
}
\newcommand{\comment}[1]{}

\title{An evaluation of some heuristic and machine learning algorithms for
  symbolic chord finding} \oneauthor {}{}
%% Teoricamente é para não botar o nome do autor no artigo, por causa
%% do processo de revisão.

\PreviewEnvironment{itemize}
\PreviewEnvironment{enumerate}


\begin{document}
\graphicspath{{figs/}{data/}}
\maketitle

\begin{abstract}

  Chord finding is an important part of harmonic analysis. Many
  algorithms have been proposed for chord finding, but there is no
  objective comparison of their main merits and flaws. Here we propose
  a novel way of evaluating chord finding algorithms using precision
  and recall instead of a plain error rate metric.
  
  We propose a k-nearest-neighbors classifier and a decision tree as
  chord labelers, and compare them agains Pardo and Birmingham's
  algorithm and Tsui's neural network.
  
  The neural network classifier is the best overall labeler for all
  chord modes in our corpus, but the k-nearest-neighbor algorithm is
  so far the best way of incorporating contextual information in the
  decision process.


\end{abstract}

\section{Introduction}
\label{sec:introduction}

Chord labels are useful metadata. Using them it is easy to see the
harmonic structure of a piece or find its progressions and
cadences. The process of manual harmonic analysis usually starts with
a rough chord labeling, that is then revised during the functional
analysis process. Many of the objectives of harmonic analysis can be
realized with proper chord labels. In this paper we will evaluate some
algorithms for automatic chord labeling of symbolic scores.

The problem of automatic chord labeling of symbolic scores has been
approached from many directions since the sixties. First, Winograd
\cite{winograd68:linguistics} and Ulrich \cite{ulrich77:analysis}
developed backtracking parsers based of formal grammars and
productions. After a hiatus they were followed by Maxwell's
\cite{maxwell92:expert} rule-based expert system and Temperley and
Sleator's preference-rule Melisma system
\cite{temperley.ea99:modeling}. By the end of the nineties Pardo and
Birmingham's HarmAn \cite{barthelemy.ea01:figured}, Barthelemy and
Bonardi's algorithm \cite{pardo.ea02:algorithms}, and Taube's
workbench \cite{taube99:automatic} were built, all using
pattern-matching as their core chord-finding method. Parallel to these
are Tsui's neural network algorithm \cite{tsui02:harmonic}, Temperley's
bayesian approach \cite{temperley04:bayesian}, and Raphael and
Stoddard's hidden Markov model \cite{raphael.ea03:harmonic}. Recently,
Illescas et al. designed a mixed system, based on rules and search
through a graph of possible solutions \cite{illescas.ea07:harmonic}.

Most of these techniques and methods were not described rigorously,
and very little source code is avaliable for testing, which is a
problem since some articles, most notably Barthelemy and Bonardi
\cite{pardo.ea02:algorithms} and Temperley and Sleator
\cite{temperley.ea99:modeling}, don't provide enough information to
reproduce their results reliably. Every benchmark found in literature
\cite{pardo.ea00:automated, pardo.ea02:algorithms, tsui02:harmonic,
  taube99:automatic, illescas.ea07:harmonic} is based only on published
examples, and this difficults a thorough statistical evaluation of the
main merits and flaws of each technique.

In this paper we present an evaluation of Pardo and Birmingham's and
Tsui's algorithms, together with two original algorithms we propose.
First, in section \ref{sec:methodology} we discuss our evaluation
methodology. In section \ref{sec:algorithms} we present Pardo et al's
HarmAn, Tsui's artificial neural networks, our decision trees and our
k-nearest-neighbors method. We compare their overall performance in
section \ref{sec:discussion} and state our case in section
\ref{sec:conclusions}.

\begin{table}
\centering
\begin{tabular}{l|l}
chord & meaning \\ \hline
    M & major chord \\
   M7 & major chord, minor seventh \\
  M7+ & major chord, major seventh \\
    m & minor chord \\
   m7 & minor chord, minor seventh \\
    ° & diminished triad \\
   °7 & fully diminished chord \\
   ø7 & half-diminished chord \\
  aug & augmented chord \\
  inc & incomplete chord \\
 aug6 & augmented sixth chord \\
  nct & non-chord tone \\
\end{tabular}
\caption{Chord labels used in this article}
\label{tab:legenda}
\end{table}

\section{Methodology}
\label{sec:methodology}

\begin{table*}
\centering
\begin{tabular}{l||r|r|r|r|r|r|r|r|r|r|r|r|r|}
      &     M &    M7 &   M7+ &     m &    m7 &    ° &   °7 &   ø7 &   aug &   inc &  aug6 &   nct \\  \hline \hline
    M & $ 507 $ & $   2 $ & $     $ & $     $ & $     $ & $     $ & $     $ & $     $ & $     $ & $     $ & $     $ & $   6 $ \\ \hline
   M7 & $     $ & $ 117 $ & $     $ & $   2 $ & $     $ & $   6 $ & $     $ & $     $ & $     $ & $     $ & $     $ & $   8 $ \\ \hline
  M7+ & $     $ & $     $ & $     $ & $     $ & $     $ & $     $ & $     $ & $     $ & $     $ & $     $ & $     $ & $  16 $ \\ \hline
    m & $   2 $ & $     $ & $     $ & $ 218 $ & $     $ & $     $ & $     $ & $     $ & $     $ & $     $ & $     $ & $   2 $ \\ \hline
   m7 & $     $ & $   2 $ & $     $ & $     $ & $  64 $ & $     $ & $     $ & $     $ & $     $ & $     $ & $     $ & $   4 $ \\ \hline
   ° & $     $ & $     $ & $     $ & $     $ & $     $ & $  65 $ & $   2 $ & $     $ & $     $ & $     $ & $     $ & $   2 $ \\ \hline
  °7 & $     $ & $     $ & $     $ & $     $ & $     $ & $     $ & $  21 $ & $     $ & $     $ & $     $ & $     $ & $   2 $ \\ \hline
  ø7 & $     $ & $     $ & $     $ & $     $ & $   2 $ & $     $ & $     $ & $  25 $ & $     $ & $     $ & $   2 $ & $     $ \\ \hline
  aug & $     $ & $     $ & $     $ & $     $ & $     $ & $     $ & $     $ & $     $ & $     $ & $     $ & $     $ & $   4 $ \\ \hline
  inc & $     $ & $   4 $ & $     $ & $   2 $ & $     $ & $     $ & $     $ & $     $ & $     $ & $     $ & $     $ & $     $ \\ \hline
 aug6 & $     $ & $     $ & $     $ & $     $ & $     $ & $     $ & $     $ & $     $ & $     $ & $     $ & $   2 $ & $     $ \\ \hline
  nct & $   5 $ & $  20 $ & $     $ & $  30 $ & $  39 $ & $   4 $ & $   2 $ & $   8 $ & $     $ & $     $ & $     $ & $ 205 $ \\ \hline
\end{tabular}

\caption{Classifications made by our best algorithm, \texttt{ES-net}. The rows represent
  the expected answers while the columns are the returned
  results. Note that the matrix is not symmetric.}
\label{tab:erros-es-net}
\end{table*}



Evaluating the performance of a chord labeling algorithm with a simple
metric such as the ratio of correct classifications might be useful to
give an idea of how well it generally works, but may hides errors in
analyzing uncommon chord types. Some chord types are often mistaken
for others, as can be seen in table \ref{tab:erros-es-net}, and some
algorithms tend to ignore less frequent chord modes, as can be seen in
table \ref{tab:erros-es-pb}.

To precisely detect each of the possible errors we propose a different
evaluation methodology. We will evaluate our algorithms by their
precision and recall with respect to each chord mode, thereby showing
the weaknesses of each algorithm.

The decision of evaluating chord labeling performance using precision
and recall is a bit unusual, and deserves justification. Here, we
assume that the aim of our algorithms is to retrieve correctly each
sonority belonging to a certain chord type from a song. We also treat
the detection of each chord type separately. Hence, every time a
diminished chord is misclassified as a non chord tone, for example,
the recall of diminished chords gets smaller, while the precision of
the non-chord tones get smaller. Having this data allows us to detect
biases in the algorithms, and highlight some of their properties. For
example, Pardo and Birmingham's algorithm, as seen in section
\ref{sec:discussion}, has a high recall and a small precision, while
the machine learning algorithms have mostly equivalent precision and
recall.

We will perform this evaluation on a corpus of 40 manually analyzed
\note{pedro: colocar frase dizendo dos gabaritos} Bach Chorales from
the Riemenschneider edition \cite{gauldin97:harmonic}. The code and data used in
this evaluation are available, together with instructions to reproduce
our analysis, at \url{http://removed-for-anonymity}.

\section{Algorithms}
\label{sec:algorithms}

\begin{table*}
\centering
\begin{tabular}{l||r|r|r|r|r|r|r|r|r|r|r|r|r|}
      &     M &    M7 &   M7+ &     m &    m7 &    ° &   °7 &   ø7 &   aug &   inc &  aug6 &   nct \\  \hline \hline
    M & $ 506 $ & $   2 $ & $     $ & $     $ & $     $ & $     $ & $     $ & $     $ & $     $ & $   8 $ & $     $ & $     $ \\ \hline
   M7 & $     $ & $ 120 $ & $   2 $ & $   2 $ & $     $ & $   6 $ & $     $ & $     $ & $     $ & $     $ & $     $ & $     $ \\ \hline
  M7+ & $     $ & $     $ & $   8 $ & $     $ & $     $ & $     $ & $     $ & $     $ & $     $ & $     $ & $     $ & $     $ \\ \hline
    m & $   2 $ & $     $ & $     $ & $ 219 $ & $     $ & $     $ & $     $ & $     $ & $     $ & $     $ & $     $ & $     $ \\ \hline
   m7 & $     $ & $   2 $ & $     $ & $   2 $ & $  55 $ & $     $ & $     $ & $  20 $ & $     $ & $     $ & $     $ & $     $ \\ \hline
   ° & $   2 $ & $     $ & $     $ & $     $ & $     $ & $  66 $ & $     $ & $     $ & $     $ & $     $ & $     $ & $     $ \\ \hline
  °7 & $     $ & $     $ & $     $ & $     $ & $     $ & $     $ & $  22 $ & $     $ & $     $ & $     $ & $     $ & $     $ \\ \hline
  ø7 & $     $ & $     $ & $     $ & $     $ & $     $ & $     $ & $     $ & $  26 $ & $     $ & $     $ & $   2 $ & $     $ \\ \hline
  aug & $     $ & $     $ & $     $ & $     $ & $     $ & $     $ & $     $ & $     $ & $   2 $ & $     $ & $     $ & $     $ \\ \hline
  inc & $     $ & $   4 $ & $     $ & $     $ & $     $ & $     $ & $     $ & $     $ & $     $ & $   1 $ & $     $ & $     $ \\ \hline
 aug6 & $     $ & $     $ & $     $ & $     $ & $     $ & $     $ & $     $ & $     $ & $     $ & $     $ & $   2 $ & $     $ \\ \hline
  nct & $ 111 $ & $  80 $ & $  72 $ & $  86 $ & $  25 $ & $  14 $ & $   2 $ & $  44 $ & $   6 $ & $  74 $ & $   4 $ & $     $ \\ \hline
\end{tabular}

\caption{Classifications made by the extended Pardo and Birmingham's algorithm. The rows represent
  the expected answers while the columns are the returned
  results. Note that many chord types are ignored.}
\label{tab:erros-es-pb}
\end{table*}

Chord labeling is a classification problem, consisting of labeling
each sonority (or sequence of sonorities) in a score with a chord
type. Most classification algorithms operate on a set of features,
that are previously extracted from the data. This is done mainly to
remove irregularities in the original inputs, reduce the
dimensionality (thereby making a problem more tractable) of the
problem, and remove noise. Each classification algorithm we present
operates on a distinct set of features, mostly derived from the
pitches of the notes. Metrical information is ignored, for now.

In this section we present Pardo and Birmingham's algorithm and a few
machine learning techniques. The machine learning algorithms were
trained on the chorales numbered 1, 2, 3, 4, 5, and 6 of the
Riemenschneider edition and on some textbook examples of augmented
<<<<<<< HEAD:harmonic-analysis-evaluation.tex
sixths, augmented chords, and major chords with major sevenths extracted
from Robert Gauldin \cite{gauldin05:harmonic} and Reginald Morris
\cite{morris33:figured}. These chorales were not used in our subsequent
evaluation.

\subsection{Pardo and Birmingham's algorithm}
\label{sec:pardo}


Pardo and Birmingham \cite{barthelemy.ea01:figured} describe a
pattern-matching algorithm for chordal analysis based on templates.
The article enumerates six templates, and the algorithm searches
across the piece for the labeling that better matches the notes found.
When a tie happens between two templates, a tie-breaking heuristic is
used (one such heuristic is ``prefer more common labelings''). In
practice, most of the non-trivial decisions made by this algorithm are
codified as tie-breaking rules, and this approach doesn't scale
well. Raphael and Stoddard describe problems common to rule based
systems \cite{raphael.ea03:harmonic}, and we have found that most of
them also apply to Pardo and Birmingham's algorithm.

Some limitations are obvious from the article. The algorithm, for
example, has no notion of a minor chord with a minor seventh, or an
augmented chord, or a chord without a third. Also, since their system
ignores enharmonic information some fine distinctions are lost, and a
german augmented sixth is shown being classified erroneously as a
dominant seventh. We have then extended the algorithm presented in the
article by incorporating more chord templates (giving a total of ten)
and enabling it to distinguish enharmonic tones, which improved the
recall of fully diminished chords and the precision in recognizing
major chords, as seen in section \ref{sec:discussion}. We have also
added inversion detection. The original algorithm is referred to as
\texttt{s-pb} and our extended version as \texttt{es-pb}.

\subsection{Decision Tree}
\label{sec:tree}

Our decision tree uses the ID3 algorithm \cite{mitchell97:machine}.
Since our decision tree library can't handle numeric attributes well,
we use the four pitch classes of each sonority to be classified as
features . This, unfortunately, makes it impossible for this algorithm
to generalize to musical styles not very similar to a four-part
chorale, although an extension to allow this is planned. This
algorithm is named \texttt{es-tree}. It distinguishes enharmonic notes
but ignores the surrounding context.

\subsection{Artificial Neural Networks}
\label{sec:neural-net}


The artificial neural networks we used are modeled after Tsui's Root
Network A \cite{tsui02:harmonic}. The main differences are in the
feature extraction process and that we consider chord types other than
major and minor. Tsui uses as features a vector, each position
containing how many times one pitch class sounds in a given
sonority. On training, Tsui's algorithm first transposes each sonority
to the 12 possible pitch classes to ensure that the network is
invariant under transposition. While interesting, this approach
becomes computationally prohibitive if one wants to distinguish
enharmonic notes. Instead, we chose to transpose each sonority so that
it has C as its lowest note. This codification also preserves
transposition invariance and allows a much simpler network structure.

We implemented two neural network algorithms: \texttt{es-net}, that
does not use contextual information, and \texttt{ec-net}, which
does. Both distinguish enharmonic notes.  It should be noted that,
unlike Tsui, our neural networks have an overall worse accuracy as
context is added, as can be seen in section \ref{sec:discussion}. Our
experiments determined that the best amount of contextual information
is the least possible, so \texttt{ec-net} looks only at one preceding
and one following sonority.


\subsection{K-Nearest-Neighbors}
\label{sec:knn}

We implemented a k-neartest-neighbors algorithm because it has good
performance and is easy to implement \cite{fix.ea89:important,
  gomez.ea04:estimating}. The features used in this classifier were the
same as in the neural networks. Our two k-nearest-neighbor algorithms,
\texttt{es-knn} and \texttt{ec-knn}, distinguish enharmonic notes, and
the only difference between them is that \texttt{es-knn} looks at one
sonority at a time, while \texttt{ec-knn} also receives information
from surrounding sonorities as input. Experimentally we have
determined that the best k value is 1, using only the nearest
neighbor, for \texttt{es-knn} and 2 for \texttt{ec-knn}. The
surrounding sonorities in \texttt{ec-knn} are weighted by a factor of
2 times their distance from the current sonority.

\section{Results}
\label{sec:discussion}


Overall, \texttt{es-net} has the best precision, recall, f-measure and
accuracy, as seen in tables \ref{tab:precision}, \ref{tab:recall},
\ref{tab:f-measure}, and \ref{tab:accuracy}. Diminished chords and
non-chord tones, as seen in table \ref{tab:f-measure}, are not
fundamentally easier to recognize without contextual
information. Augmented chords, on the other hand, appear to require
context to be recognized by machine learning algorithms.

The high performance of \texttt{ES-knn},as seen in table
\ref{tab:f-measure}, suggests that smarter templates might boost the
performance of \texttt{ES-PB}, since both algorithms work as glorified
template matchers. \texttt{s-pb} and \texttt{es-pb} have very good
recall but terrible precision, probably due to their discarding of
non-chord tones, as can be seen in table \ref{tab:erros-es-pb}. 

Averaged f-measure over all chord types is, as expected, highly
correlated with overall accuracy, as seen it table \ref{tab:accuracy}.


\begin{table}
  \centering
\begin{tabular}{l|p{0.5cm}p{0.5cm}p{0.5cm}p{0.5cm}p{0.5cm}p{0.5cm}p{0.5cm}}
    &      EC-Knn &      EC-net &      ES-Knn &       ES-PB &      ES-net &     ES-tree &        S-PB   \\ \hline
M   & $     88.6$ & $     95.0$ & $     95.7$ & $     89.7$ & $     99.3$ & $     87.5$ & $     70.7$   \\
M7  & $     82.6$ & $     92.9$ & $     89.1$ & $     74.0$ & $     93.0$ & $     82.5$ & $     73.5$   \\
M7+ & $     66.7$ & $     75.0$ & $      0.0$ & $     19.5$ & $      0.0$ & $      0.0$ & $      0.0$   \\
m   & $     83.7$ & $     90.0$ & $     89.4$ & $     83.3$ & $     92.3$ & $     84.1$ & $     83.3$   \\
m7  & $     61.8$ & $     64.5$ & $     70.0$ & $     84.2$ & $     76.7$ & $     54.4$ & $      0.0$   \\
°   & $     82.8$ & $     79.2$ & $     87.9$ & $     88.2$ & $     92.2$ & $     66.0$ & $     83.6$   \\
°7  & $     86.7$ & $     69.2$ & $    100$ & $     90.0$ & $     94.4$ & $     57.9$ & $    100$   \\
ø7  & $     76.5$ & $     53.3$ & $     95.7$ & $     49.1$ & $     81.2$ & $     69.2$ & $     48.2$   \\
aug & $      0.0$ & $     40.0$ & $      0.0$ & $     50.0$ & $      0.0$ & $      0.0$ & $      0.0$   \\
inc & $      0.0$ & $      0.0$ & $      0.0$ & $      2.6$ & $      0.0$ & $      0.0$ & $      0.0$   \\
aug6& $    100$ & $     33.3$ & $    100$ & $     25.0$ & $    100$ & $      0.0$ & $      0.0$   \\
nct & $     74.9$ & $     78.4$ & $     83.8$ & $      0.0$ & $     88.8$ & $     74.9$ & $      0.0$   \\
avg & $     82.7$ & $     86.2$ & $     90.0$ & $     78.6$ & $     93.2$ & $     80.3$ & $     73.8$   \\
\end{tabular}


  \caption{Precision (\%)}
  \label{tab:precision}
\end{table}

\begin{table}
  \centering
\begin{tabular}{l|p{0.5cm}p{0.5cm}p{0.5cm}p{0.5cm}p{0.5cm}p{0.5cm}p{0.5cm}p{0.5cm}}
    &      EC-Knn &      EC-net &      ES-Knn &       ES-PB &      ES-net &     ES-tree &      S-PB \\ \hline
M   & $     95.4$ & $     96.0$ & $     98.9$ & $     99.1$ & $     99.3$ & $     96.7$ & $    100.0$ \\
M7  & $     77.6$ & $     79.3$ & $     91.4$ & $     95.7$ & $     92.2$ & $     56.9$ & $     95.7$ \\
M7+ & $     25.0$ & $     37.5$ & $      0.0$ & $    100.0$ & $      0.0$ & $      0.0$ & $      0.0$ \\
m   & $     89.8$ & $     92.2$ & $     98.5$ & $     99.5$ & $     99.0$ & $     89.8$ & $     99.5$ \\
m7  & $     72.4$ & $     84.5$ & $     84.5$ & $     82.8$ & $     96.6$ & $     64.9$ & $      0.0$ \\
°   & $     77.4$ & $     67.7$ & $     93.5$ & $     96.8$ & $     95.2$ & $     53.2$ & $     98.4$ \\
°7  & $     72.2$ & $     50.0$ & $     66.7$ & $    100.0$ & $     94.4$ & $     61.1$ & $     83.3$ \\
ø7  & $     48.1$ & $     59.3$ & $     81.5$ & $     96.3$ & $     96.3$ & $     66.7$ & $    100.0$ \\
aug & $      0.0$ & $    100.0$ & $      0.0$ & $    100.0$ & $      0.0$ & $      0.0$ & $      0.0$ \\
inc & $      0.0$ & $      0.0$ & $      0.0$ & $     33.3$ & $      0.0$ & $      0.0$ & $      0.0$ \\
aug6& $    100.0$ & $    100.0$ & $    100.0$ & $    100.0$ & $    100.0$ & $      0.0$ & $      0.0$ \\
nct & $     66.4$ & $     79.0$ & $     72.1$ & $      0.0$ & $     79.9$ & $     70.0$ & $      0.0$ \\
avg & $     82.7$ & $     86.2$ & $     90.0$ & $     78.6$ & $     93.2$ & $     80.3$ & $     73.7$ \\
\end{tabular}


  \caption{Recall (\%)}
  \label{tab:recall}
\end{table}


\begin{table}
  \centering
\begin{tabular}{l|p{0.5cm}p{0.5cm}p{0.5cm}p{0.5cm}p{0.5cm}p{0.5cm}p{0.5cm}p{0.5cm}}
     &      EC-Knn &      EC-net &      ES-Knn &       ES-PB &      ES-net &     ES-tree &      S-PB \\ \hline
M    & $     91.9$ & $     95.5$ & $     97.3$ & $     94.2$ & $     99.3$ & $     91.9$ & $     82.8$ \\
M7   & $     80.0$ & $     85.6$ & $     90.2$ & $     83.5$ & $     92.6$ & $     67.3$ & $     83.1$ \\
M7+  & $     36.4$ & $     50.0$ & $      0.0$ & $     32.6$ & $      0.0$ & $      0.0$ & $      0.0$ \\
m    & $     86.6$ & $     91.1$ & $     93.7$ & $     90.7$ & $     95.5$ & $     86.9$ & $     90.7$ \\
m7   & $     66.7$ & $     73.2$ & $     76.6$ & $     83.5$ & $     85.5$ & $     59.2$ & $      0.0$ \\
°    & $     80.0$ & $     73.0$ & $     90.6$ & $     92.3$ & $     93.7$ & $     58.9$ & $     90.4$ \\
°7   & $     78.8$ & $     58.1$ & $     80.0$ & $     94.7$ & $     94.4$ & $     59.5$ & $     90.9$ \\
ø7   & $     59.1$ & $     56.1$ & $     88.0$ & $     65.0$ & $     88.1$ & $     67.9$ & $     65.0$ \\
aug  & $      0.0$ & $     57.1$ & $      0.0$ & $     66.7$ & $      0.0$ & $      0.0$ & $      0.0$ \\
inc  & $      0.0$ & $      0.0$ & $      0.0$ & $      4.8$ & $      0.0$ & $      0.0$ & $      0.0$ \\
aug6 & $    100.0$ & $     50.0$ & $    100.0$ & $     40.0$ & $    100.0$ & $      0.0$ & $      0.0$ \\
nct  & $     70.4$ & $     78.7$ & $     77.5$ & $      0.0$ & $     84.1$ & $     72.4$ & $      0.0$ \\
avg  & $     82.7$ & $     86.2$ & $     90.0$ & $     78.6$ & $     93.2$ & $     80.3$ & $     73.7$ \\
\end{tabular}


  \caption{F-measure (\%)}
  \label{tab:f-measure}
\end{table}



\begin{table}
  \centering
  \begin{tabular}{l|rrr}
       & accuracy& $\sigma$  & f-measure\\
\hline
es-net &$   93  $&$  3$      &$93.2$ \\
es-knn &$   90  $&$  3$      &$90.0$ \\
ec-net &$   85  $&$  4$      &$86.5$ \\
ec-knn &$   82  $&$  3$      &$82.7$ \\
es-pb  &$   79  $&$  6$      &$78.6$ \\
es-tree&$   79  $&$  7$      &$72.4$ \\
s-pb   &$   66  $&$ 17$      &$73.7$ \\

  \end{tabular}                                                        


  \caption{Overall Accuracy (\%)}
  \label{tab:accuracy}
\end{table}

\section{Conclusions and future work}
\label{sec:conclusions}

We have evaluated algorithms for chord labeling of symbolic scores of
tonal music on a corpus of 40 Bach chorales and have found that an
artificial neural network that does not use contextual information is
the best algorithm evaluated. We have also found that a simple
memory-based classifier can outperform some heuristic algorithms. We
also presented a modification to the algorithm described in
\cite{barthelemy.ea01:figured} that is demonstrably better.

We will continue to reimplement, test, and benchmark algorithms for
automated chord labeling and harmonic analysis, starting with Raphael
and Stoddard's hidden Markov model \cite{raphael.ea03:harmonic} and
Maxwell's expert system \cite{maxwell92:expert}.  We will also extend
our test corpus to incorporate Beethoven sonatas, the Kostka-Payne
corpus \cite{temperley04:bayesian}, Bach partitas, and other
representative tonal pieces. Our aim is to benchmark and study the
whole harmonic analysis process, from pitch spelling to functional and
non-chord tone analysis.

\bibliographystyle{plain}
\bibliography{strings-short,ismir,programs,coding,harmonic-analysis,dont-have,artifical-inteligence,music-harmony-and-theory,licenses,icmc,music-scores}

\end{document}

