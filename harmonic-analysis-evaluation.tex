\documentclass{article}
\usepackage{ismir}
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage{url}
\usepackage[utf8x]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[english]{babel}
%\usepackage[htt]{hyphenat}
\usepackage{times}
\usepackage{color}

\newcounter{notecounter}

\newcommand{\note}[1]{
  \addtocounter{notecounter}{1}
  \textcolor{red}{[note \arabic{notecounter}: #1]}
}

\newcommand{\comment}[1]{}

\title{An evaluation of heuristic and machine learning algorithms for
  symbolic chord finding} \oneauthor {
%% Teoricamente é para não botar o nome do autor no artigo, por causa
%% do processo de revisão.
}


\begin{document}
\graphicspath{{figs/}{data/}}
\maketitle

\begin{abstract}
\end{abstract}

\section{Introduction}
\label{sec:introduction}

\comment{
  ==> chord finding é importante, vários algoritmos propostos, poucas
  comparações 
  ==> revisar algoritmos
  ==> descrever artigo
}

Chords are useful metadata. When an analyst perform harmonic analysis
of a piece of tonal music he starts by noting where and what the
possible chords are. Then, he uses this information to find the
piece's tonality, cadence, modulations and overall structure. After
analysis he can use this acquired information as he wishes, to, for
example, understand the harmony of that piece, find other similar
songs, or write an accompaniment. Finding the chords of a piece of
tonal music is just metadata extraction, and the study of chord
finding as such can increse understanding of the performance and
limitations of current techniques.

The problem of automated finding the chord structure of symbolic
scores has been approached from many directions, mostly mirroring
approaches to natural language processing currently in fashion.
First, Winograd \cite{winograd:linguistics} and Ulrich
\cite{ulrich:analysis} developed backtracking parsers based of formal
grammars and productions. After a hiatus they were followed by
Maxwell's \cite{maxwell:expert} production rule-based expert system
and Temperley and Sleator's Melisma \cite{temperley.ea:modeling},
based on preference rules. These were followed by Pardo and
Birmingham's HarmAn \cite{pardo.ea:automated}, Barthelemy and Bonardi
\cite{barthelemy.ea:figured} and Taube's workbench
\cite{taube:automatic}, all built using pattern-matching as their core
chord-finding method. Following these are Tsui's \cite{tsui:harmonic}
neural network algorithm and Temperley's \cite{temperley:bayesian}
bayesian approach.

Here we present an evaluation Pardo and Birmingham's, Maxwell's,
Tsui's and two orignal algorithms. First, in section
\ref{sec:methodology} we discuss our evaluation methodology. In
section \ref{sec:algorithms} we present Pardo et al's HarmAn,
Maxwell's algorithms, Tsui's artificial neural networks, our decision
trees and a baseline k-nearest-neighbours method. We compare their
overall performance in section \ref{sec:discussion} and state our case
in section \ref{sec:conclusions}.

\section{Methodology}
\label{sec:methodology}

\comment{
  ==> um problema de information retrieval
  ==> precision, recall (e significado)
  ==> corais de bach
}

All these techniques and methods were described informally, and very
little source code is avaliable for testing. Some articles, most
notably Barthelemy and Bonardi \cite{barthelemy.ea:figured} and
Temperley and Sleator \cite{temperley.ea:modeling}, don't provide
enough information to reproduce their results reliably. Every
benchmark found in literature \cite{pardo.ea:automated,
  barthelemy.ea:figured, tsui:harmonic, taube:automatic,
  illescas.ea:harmonic} is only based on published examples, and this
difficults a thorough statistical evaluation of each technique's main
merits and flaws.

Chord finding in a tonal piece is definitely not trivial. While it is
possible to make a good guess just by looking at the notes in a
sonority, this guess is often wrong, and it is impossible to tell
exactly how it is wrong without looking at the surrounding
context. Also, many times a sonority might seem to form a chord, but
that chord could have no tonal function in that part of the piece,
and, instead, one or more of those notes are there for purely melodic
purposes. For example, figure \nota{passos: botar figura do exemplo
  v->acorde que parece diminuto->v7->i} shows a dominant chord that,
in passing to a dominant chord with minor seventh, forms a
configuration similar to that of a diminished chord. Therefore, some
form of contextual information is necessary to correctly label a
chord.

A chord finding algorithm has to decide which of the possible
labelings is best for a given sonority. Evaluating its performance
with a simple metric such as the ratio of correct classifications
might be useful to give an idea of how well it generally works, but
hides many defficiencies in the less common chord types. For example,
correctly labeling major chords, minor chords and non-chord tones in
our corpus is enough to get a $77\%$ accuracy. Also, some chord modes
are often mistaken for others (for example, a minor seventh chord
might have the same notes as a major chord) and some algorithms tend
to ignore less frequent chord modes. For these reasons we propose a
different evaluation methodology. We will use a baseline algorithm,
k-nearest-neighbours, to assess how much can be done by just
remembering previous classifications. We will also evaluate our
algorithms by their precision and recall with respect to each chord
mode, thereby showing where each most easily fails; and we will
compute the bias of each algorithm regarding each chord mode.

\section{Algorithms}
\label{sec:algorithms}

\comment{
  ==> features usadas pelos algoritmos
  ==> técnicas variadas: busca X learning
}



\subsection{Pardo and Birmingham's algorithm}
\label{sec:pardo}

\comment{
  ==> algoritmo descrito em \cite{pardo.ea:algorithms}
  ==> baseado em templates e pattern matching
  ==> ótima recall, precisão não muito legal
  ==> ignora enarmonia
  ==> feature é um conjunto de pitches
  ==> nossa extensão:
  ===> mais templates
  ===> enarmonia
  ==> regras de desempate: a princípio promissoras, mas a abordagem
  não escala bem
}

Pardo and Birmingham \cite{pardo.ea:algorithms} describe a
pattern-matching algorithm for chordal analysis based on
templates. The article enumerates six such templates, and the
algorithm searches across the piece for the labeling that better
matches the notes found.

Some limiations are obvious from the article. The algorithm, for
example, has no notion of a minor chord with a minor seventh, or an
augmented chord, or a chord without a third (and, consequently, having
a melodic purpose on the piece). Also, since their system ignores
enharmonic information some fine distinctions are lost, and a german
augmented sixth is shown being classified as a dominant seventh.

We have extended the algorithm presented in the article by
incorporating more chord templates (giving a total of 10 chord
templates) and giving it access to enharmonic information, which
improved the recall of fully diminished chords and the precision in
recognizing major chords. We have also added a bass note detection.

\subsection{Maxwell's expert system}
\label{sec:maxwell}


\subsection{Decision Trees}
\label{sec:tree}

\comment{
  ==> ID3 algorithm
  ==> features: sequência de pitches
  ==> dependência em quatro vozes 
}

Our decision trees use the ID3 algorithm
\cite{mitchell:machine}. Since our decision tree library can't handle
numeric attributes well, the features we chose were the four pitch
classes of each sonority to be classified. This, unfortunately,
makes it impossible for these algorithms to generalize to musical
styles not very similar to a four-part chorale.

We have implemented two decision trees: \texttt{s-tree} and
\texttt{es-tree}. The only difference between them is that
\texttt{es-tree} distinguishes enharmonic notes.

\subsection{Artificial Neural Networks}
\label{sec:neural-net}

\comment{
  ==> features são weighted pitch counts
  ==> simple/enharmonic-simple/context
}

The artificial neural networks we used are modeled after Tsui's Root
Network A \cite{tsui:harmonic}. The main differences are in the
feature extraction process and that we consider more chord types than
major and minor. Tsui \cite{tsui:harmonic} uses as features a vector,
each position representing one pitch class. On training, he first
transposes every sonority to the 12 possible pitch classes to ensure
that the network is transposition-invariant. While interesting, this
approach becomes computationally prohibitive if one wants to
distinguish enharmonic notes. Instead, we chose to transpose each
sonority so that it has C as its bass note. This codification has
interesting properties and has no accuracy burden.

We have three neural network algorithms: \texttt{s-net},
\texttt{es-net} and \texttt{ec-net}. \texttt{s-net} looks at one
sonority at a time and discards enharmonic information. \textt{es-net}
looks at one sonority at a time but distinguishes enharmonic
notes. \texttt{ec-net} is equivalent to \texttt{es-net}, but looks
also at the surrounding context of a sonority.

\subsection{K-Nearest-Neighbors}
\label{sec:knn}

\comment{
  ==> baseline (similar a pardo, templates automaticos)
  ==> good theoretical performance (citar \cite{fix.ea:important}) 
  ==> very good practical performance (citar
  \cite{gomez.ea:estimating})
}

The k-nearest-neighbors algorithm is one of the simplest techniques
used in Machine Learning (along with the naive bayes classifier and
decision trees). It represents each training input as a point in a
multidimensional space and classifies each input by choosing the
classification most similar to the k nearest training points. As
simple as it may seem, the k-nearest-neighbor algorithm is guaranteed,
on sufficient data points, to yield an error rate at most twice the
maximum possible given the distribution of the data
\cite{fix.ea:important}.

The features used in this classifier were the same as in the neural
networks. We have two k-nearest-neighbor algorithms, \texttt{es-knn}
and \texttt{ec-knn}. They both distinguish enharmonic notes. The only
difference between them is that \texttt{es-knn} looks at one sonority
at a time, while \texttt{ec-knn} also receives information from
surrounding sonorities as input.

\section{Discussion}
\label{sec:discussion}



\section{Conclusions}
\label{sec:conclusions}


\bibliographystyle{plain}
\bibliography{strings-short,ismir,programs,coding,harmonic-analysis,dont-have,artifical-inteligence,music-harmony-and-theory,licenses,icmc}

\end{document}

